### CI Pipeline Explanation

In a **CI (Continuous Integration) pipeline**, each stage has a specific purpose to ensure that the code is built, tested, analyzed, and packaged correctly before it is deployed. Here's a breakdown of the pipeline you mentioned and how each stage functions in the context of CI.

### **Stage 1: Checkout the source code from Git**
This is the first step of any CI pipeline. The goal here is to fetch the latest version of the source code from the repository.

**Explanation:**
- The pipeline will connect to a Git repository (e.g., GitHub, GitLab, Bitbucket) and **checkout** the latest code from the specific branch (usually `main` or a feature branch).
- This ensures that the code in the pipeline is up to date.

**Example:**
```bash
git clone https://github.com/your-repo/project.git
```

---

### **Stage 2: Build the Java application using Maven**
In this stage, the pipeline compiles the source code into a **binary format**, usually a `.jar` file (for Java).

**Explanation:**
- **Maven** is a build automation tool that compiles the source code, resolves dependencies, and packages the application into a distributable format.
- Maven will run a `clean` and `package` goal to ensure any old artifacts are removed and the application is recompiled from scratch.
- During the build process, Maven will also fetch any dependencies specified in the `pom.xml` file.

**Command Example:**
```bash
mvn clean package
```

---

### **Stage 3: Run unit tests using JUnit and Mockito**
In this stage, **unit tests** are run on the source code to check its functionality and correctness.

**Explanation:**
- **JUnit** is a widely used testing framework for Java applications.
- **Mockito** is a mocking framework often used in unit tests to mock dependencies (like database or external services) so tests can be isolated.
- The tests are run **during the build process** (usually part of the Maven build), and results are reported. If any tests fail, the pipeline will fail and the issue will be flagged.
- These unit tests are run **on the code that is checked out** in **Stage 1** ‚Äî meaning the latest code from the repository.

**Command Example:**
```bash
mvn test
```

---

### **Stage 4: Run SonarQube analysis to check the code quality**
In this stage, **SonarQube** is used to perform static analysis on the source code. It checks for things like:
- Code smells (bad code design or practices)
- Bugs
- Vulnerabilities
- Test coverage
- Duplicated code

**Explanation:**
- SonarQube analyzes the code in the repository to provide insights into the **quality of the code**.
- The analysis runs on the same code that was checked out in **Stage 1**.
- If any issues are found, the analysis will provide a detailed report, and depending on the configuration, the pipeline may fail or continue with a warning.

**Command Example:**
```bash
mvn sonar:sonar -Dsonar.projectKey=my_project
```

---

### **Stage 5: Package the application into a JAR file**
After the code is compiled and tested, the application is packaged into a distributable format, usually a **JAR** file (Java ARchive).

**Explanation:**
- The packaging step will generate a `.jar` file from the compiled code and dependencies.
- The `.jar` file is the actual **artifact** that will be deployed and run in the production environment.
- This `.jar` file is generated by Maven in the **previous step**. The Maven command (`mvn clean package`) already packages the application, so this stage is usually about **finalizing** the artifact and moving it to a storage location (e.g., a repository or a Docker image).

---

### **Docker Image Building and Pushing**
The Docker image building and pushing step typically comes **after the artifact is created** (after Stage 5). 

Here‚Äôs why:
- You want to ensure that the code has passed all tests, has been analyzed by SonarQube, and is packaged correctly **before** you build a Docker image.
- The Docker image will contain the **JAR file** along with everything needed to run the application.

**Explanation:**
- **Docker Image**: The Docker image is a portable, self-contained environment that includes the application and all of its dependencies. This is what you will run in production.
- **Push**: After building the Docker image, it needs to be pushed to a Docker registry (e.g., Docker Hub, AWS ECR) so it can be pulled by other environments or machines for deployment.

---

### **Where Does Docker Image Building and Pushing Happen in the Pipeline?**

After you have successfully built the JAR file and performed the tests and analysis, you proceed with **building the Docker image** in a separate stage. Here's a breakdown:

```groovy
stage('Build Docker Image') {
    steps {
        script {
            sh 'docker build -t my-app:$BUILD_ID .'
        }
    }
}

stage('Push Docker Image') {
    steps {
        script {
            withCredentials([usernamePassword(credentialsId: 'dockerhub-credentials-id', usernameVariable: 'DOCKER_USERNAME', passwordVariable: 'DOCKER_PASSWORD')]) {
                sh 'echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin'
                sh 'docker push my-app:$BUILD_ID'
            }
        }
    }
}
```

- In **Build Docker Image**, the Docker image is built using the JAR file generated earlier.
- In **Push Docker Image**, the image is pushed to a Docker registry.

---

### **CI Workflow Recap**

1. **Checkout** the latest code from Git.
2. **Build** the Java app using Maven.
3. **Run unit tests** (JUnit, Mockito) on the source code.
4. **Run SonarQube analysis** to check code quality.
5. **Package** the app into a JAR file using Maven.
6. **Build a Docker image** with the JAR file.
7. **Push the Docker image** to a registry (Docker Hub, ECR, etc.).

---

### **Why Unit Tests and SonarQube Analysis Are Separate from the JAR Packaging (Step 5)**

- **Unit Tests (Stage 3)** and **SonarQube analysis (Stage 4)** run **before packaging the JAR** to ensure that the code is working and of good quality **before creating a deployable artifact**.
- If tests fail or SonarQube detects critical issues, the build is halted. You wouldn't want to create a JAR or a Docker image with broken code or poor quality.
- **Packaging the JAR (Stage 5)** is only done **after** these checks to ensure that you have a working and clean codebase ready for deployment.

---

Great! Let‚Äôs walk through the **Complete CD (Continuous Deployment) process** where:

- You have **Jenkins running on EC2-1**.
- You have a **Kubernetes cluster running on EC2-2**.
- Your app is **already containerized** (Docker image pushed to DockerHub from the CI process).
- Jenkins will trigger a deployment on Kubernetes using **`kubeconfig`**.

---

## ‚úÖ Overview of What You‚Äôll Do

1. **Push Docker image to DockerHub** (already done in CI).
2. **Setup K8s cluster on EC2-2**.
3. **Expose K8s API Server** on EC2-2 to allow Jenkins to access it.
4. **Generate and copy kubeconfig file** from EC2-2 to EC2-1 (Jenkins).
5. **Add kubeconfig as Jenkins credentials**.
6. **Jenkinsfile** will use the kubeconfig to run `kubectl apply -f deployment.yaml`.

---

## üîç Step-by-Step Explanation

### üß† What is `kubeconfig`?

- `kubeconfig` is a file that contains **connection details**, **certificates**, and **auth tokens** to access a Kubernetes cluster.
- It allows `kubectl` to connect and authenticate to the Kubernetes **API server**.
- Default location: `~/.kube/config`

---

## üîß Step-by-Step: CD with Jenkins + K8s (on separate EC2s)

---

### ‚úÖ 1. Create Kubernetes Cluster on EC2-2

You can use `kubeadm` for a minimal setup:
```bash
sudo apt-get update
sudo apt-get install -y docker.io
sudo systemctl enable docker && sudo systemctl start docker
sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo kubeadm init --pod-network-cidr=192.168.0.0/16
```

Post init:
```bash
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```

Install pod network:
```bash
kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
```

‚úÖ Now Kubernetes is running on EC2-2.

---

### ‚úÖ 2. Expose the Kubernetes API server (EC2-2)

By default, API server listens on `127.0.0.1`. You need to change it to listen on **external IP**.

1. Edit Kubernetes API server manifest:
```bash
sudo nano /etc/kubernetes/manifests/kube-apiserver.yaml
```

2. Look for `--advertise-address=127.0.0.1`, change to:
```yaml
--advertise-address=<EC2-2-private-or-public-IP>
```

3. Also make sure EC2-2's security group allows **port 6443** inbound from EC2-1 (Jenkins node).

Then reboot kubelet:
```bash
sudo systemctl restart kubelet
```

---

### ‚úÖ 3. Copy kubeconfig to EC2-1 (Jenkins)

From EC2-2 (K8s node):
```bash
scp ~/.kube/config ubuntu@<EC2-1-PUBLIC-IP>:/home/ubuntu/kubeconfig
```

Now EC2-1 has `kubeconfig`.

You can verify from EC2-1:
```bash
KUBECONFIG=/home/ubuntu/kubeconfig kubectl get nodes
```

If successful, Jenkins can use this file.

---

### ‚úÖ 4. Add `kubeconfig` as Jenkins Credentials

1. Go to **Jenkins ‚Üí Manage Jenkins ‚Üí Credentials**.
2. Choose (global) ‚Üí Add Credentials.
3. Type: **Secret file**
4. Upload the `/home/ubuntu/kubeconfig` file.
5. ID: `kubeconfig`

---

### ‚úÖ 5. Jenkinsfile for CD (Deployment to K8s)

Your `Jenkinsfile` should have a deployment stage like:

```groovy
pipeline {
  agent any

  environment {
    KUBECONFIG_CRED = credentials('kubeconfig')
    IMAGE_NAME = 'khushi0311/simple-springboot-app'
  }

  stages {
    stage('Deploy to K8s') {
      steps {
        withCredentials([file(credentialsId: 'kubeconfig', variable: 'KUBECONFIG')]) {
          sh '''
            echo "Deploying to Kubernetes"
            export KUBECONFIG=$KUBECONFIG

            kubectl set image deployment/my-app my-app=$IMAGE_NAME --namespace=default || \
            kubectl apply -f k8s/deployment.yaml
          '''
        }
      }
    }
  }
}
```

---

## ‚úÖ Your `k8s/deployment.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app
        image: khushi0311/simple-springboot-app
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  selector:
    app: my-app
  ports:
  - port: 80
    targetPort: 8080
  type: LoadBalancer
```

---

### ‚úÖ Summary

| Step | Action |
|------|--------|
| 1 | Jenkins builds & pushes Docker image to DockerHub |
| 2 | K8s is running on EC2-2 and exposes its API |
| 3 | EC2-1 (Jenkins) uses `kubeconfig` to talk to K8s |
| 4 | Jenkins CD stage deploys Docker image to Kubernetes using `kubectl` |
| 5 | Jenkins uses credentials to safely access the kubeconfig file |

---

